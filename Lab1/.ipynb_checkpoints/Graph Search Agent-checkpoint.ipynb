{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Search Agent\n",
    "\n",
    "The graph search agent requires an environment to define the following\n",
    "\n",
    "1. Start State\n",
    "2. Goal State\n",
    "3. Possible Actions\n",
    "\n",
    "We have to make a generalised agent, which reaches the goal state using the functions of the environment. Our agent will use BFS/DFS to reach to the goal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node\n",
    "The Node class greates the graph node. It has the following values\n",
    "1. Parent Node\n",
    "2. State \n",
    "3. Cost\n",
    "\n",
    "It makes use of the following built in functions: \n",
    "1. \\_\\_hash\\_\\_ : This provides the hash value for every node, which is required for the hashset\n",
    "2. \\_\\_eq\\_\\_ : To check if 2 nodes are equal (Operator overload)\n",
    "3. \\_\\_ne\\_\\_ : To check if 2 nodes are not equal (Operator overload)\n",
    "4. \\_\\_str\\_\\_ : To get string representation of state in node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, cost):\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.cost = cost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten()))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorityQueue\n",
    "The Priority Queue is used to store the nodes along with the cost, and pop the node having the least cost for BFS\n",
    "\n",
    "It makes use of the following functions: \n",
    "1. push : Add node to queue\n",
    "2. pop : Pop node having least cost\n",
    "3. is_empty : To check if queue is empty\n",
    "4. \\_\\_len\\_\\_ : To get length of queue\n",
    "5. \\_\\_str\\_\\_ : To get string representation of queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        \n",
    "    def push(self, node):\n",
    "        self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        \n",
    "        next_state = None\n",
    "        state_cost = 10**18\n",
    "        index = -1\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if self.queue[i].cost<state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        \n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        \n",
    "        return len(self.queue)==0\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)\n",
    "        \n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "The environment is what the agent plays in. It has the following entities:\n",
    "1. actions : The actions defined in the environment\n",
    "2. depth: the maximum depth of the solution\n",
    "3. goal_state : The goal state of the environment\n",
    "4. start_state : The start state generated at the depth\n",
    "\n",
    "It has the following functions: \n",
    "1. get_start_state : returns the start state\n",
    "2. reached_goal : returns goal_state\n",
    "3. get_next_states : Given current state, it returns all possible next states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    def __init__(self, depth = None, goal_state = None):\n",
    "        self.actions = [1,2,3,4] #1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
    "        self.goal_state = goal_state\n",
    "        self.depth = depth\n",
    "        self.start_state = self.generate_start_state()\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        \n",
    "        past_state = goal_state\n",
    "        i=0\n",
    "        while i!= self.depth:\n",
    "            new_states = self.get_next_states(past_state)\n",
    "            choice = np.random.randint(low=0, high=len(new_states))\n",
    "            \n",
    "            if np.array_equal(new_states[choice], past_state):\n",
    "                continue\n",
    "            \n",
    "            past_state = new_states[choice]\n",
    "            i+=1\n",
    "            \n",
    "        return past_state\n",
    "    \n",
    "    def get_start_state(self):\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        \n",
    "        space = (0,0)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] == '_':\n",
    "                    space = (i,j)\n",
    "                    break\n",
    "        \n",
    "        new_states = []\n",
    "        \n",
    "        if space[0] > 0:# Move Up\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]-1, space[1]]\n",
    "            new_state[space[0]-1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[0] < 2: #Move down\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]+1, space[1]]\n",
    "            new_state[space[0]+1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        if space[1]<2: #Move right\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]+1]\n",
    "            new_state[space[0], space[1]+1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[1] > 0: #Move Left\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]-1]\n",
    "            new_state[space[0], space[1]-1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] != self.goal_state[i,j]:\n",
    "                    return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "The agent is the player who plays the game against the environment to win. It has the following entities:\n",
    "1. frontier : This is the priority queue used to store the nodes to be explored.\n",
    "2. explored : This is the dictionary which stores the explored nodes\n",
    "3. start_state : Stores the start state\n",
    "4. goal_state : Stores the goal state\n",
    "5. env : Stores the environment\n",
    "6. goal_node : Stores the goal node if found\n",
    "7. heuristic : Stores the heuristic function\n",
    "\n",
    "The agent has the following functions: \n",
    "1. run(): Is the function that explores the environment and finds the goal node. Uses the built in heuristic function to get the path costs\n",
    "2. print_nodes(): To print the path from the start node to goal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, start_state, goal_state, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = start_state\n",
    "        self.goal_state = goal_state\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, cost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            #print(curr_node.cost)\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "\n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            l = []\n",
    "            for state in next_states:\n",
    "\n",
    "                hcost = self.heuristic(state, goal_state)\n",
    "                node = Node(parent=curr_node, state=state, cost=curr_node.cost+1)\n",
    "                self.frontier.push(node)\n",
    "            \n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Step: \",step)\n",
    "            print(node)\n",
    "            step+=1\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the environment cannot spawn its own start and end states, we input the start state and end state to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic0(curr_state, goal_state):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic1(curr_state, goal_state):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if curr_state[i, j]!=goal_state[i,j]:\n",
    "                count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic2(curr_state, goal_state):\n",
    "    \n",
    "    dist = 0\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ele = curr_state[i, j]\n",
    "            goal_i, goal_j = np.where(goal_state==ele)\n",
    "            d = abs(goal_i[0] - i) + abs(goal_j[0] - j)\n",
    "            dist += d\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State: \n",
      "[['2' '4' '6']\n",
      " ['8' '_' '3']\n",
      " ['7' '1' '5']]\n",
      "Goal State: \n",
      "[['1' '2' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '6' '5']]\n"
     ]
    }
   ],
   "source": [
    "depth = 100\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "env = Environment(depth, goal_state)\n",
    "print(\"Start State: \")\n",
    "print(env.get_start_state())\n",
    "print(\"Goal State: \")\n",
    "print(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env.get_start_state(), env.get_goal_state(), env, heuristic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n"
     ]
    }
   ],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  1\n",
      "[['2' '4' '6']\n",
      " ['8' '_' '3']\n",
      " ['7' '1' '5']]\n",
      "Step:  2\n",
      "[['2' '_' '6']\n",
      " ['8' '4' '3']\n",
      " ['7' '1' '5']]\n",
      "Step:  3\n",
      "[['2' '6' '_']\n",
      " ['8' '4' '3']\n",
      " ['7' '1' '5']]\n",
      "Step:  4\n",
      "[['2' '6' '3']\n",
      " ['8' '4' '_']\n",
      " ['7' '1' '5']]\n",
      "Step:  5\n",
      "[['2' '6' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '1' '5']]\n",
      "Step:  6\n",
      "[['2' '6' '3']\n",
      " ['8' '1' '4']\n",
      " ['7' '_' '5']]\n",
      "Step:  7\n",
      "[['2' '6' '3']\n",
      " ['8' '1' '4']\n",
      " ['_' '7' '5']]\n",
      "Step:  8\n",
      "[['2' '6' '3']\n",
      " ['_' '1' '4']\n",
      " ['8' '7' '5']]\n",
      "Step:  9\n",
      "[['2' '6' '3']\n",
      " ['1' '_' '4']\n",
      " ['8' '7' '5']]\n",
      "Step:  10\n",
      "[['2' '_' '3']\n",
      " ['1' '6' '4']\n",
      " ['8' '7' '5']]\n",
      "Step:  11\n",
      "[['_' '2' '3']\n",
      " ['1' '6' '4']\n",
      " ['8' '7' '5']]\n",
      "Step:  12\n",
      "[['1' '2' '3']\n",
      " ['_' '6' '4']\n",
      " ['8' '7' '5']]\n",
      "Step:  13\n",
      "[['1' '2' '3']\n",
      " ['8' '6' '4']\n",
      " ['_' '7' '5']]\n",
      "Step:  14\n",
      "[['1' '2' '3']\n",
      " ['8' '6' '4']\n",
      " ['7' '_' '5']]\n",
      "Step:  15\n",
      "[['1' '2' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '6' '5']]\n"
     ]
    }
   ],
   "source": [
    "agent.print_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
