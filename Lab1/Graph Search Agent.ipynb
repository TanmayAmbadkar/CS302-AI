{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Search Agent\n",
    "\n",
    "The graph search agent requires an environment to define the following\n",
    "\n",
    "1. Start State\n",
    "2. Goal State\n",
    "3. Possible Actions\n",
    "\n",
    "We have to make a generalised agent, which reaches the goal state using the functions of the environment. Our agent will use BFS/DFS to reach to the goal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node\n",
    "The Node class greates the graph node. It has the following values\n",
    "1. Parent Node\n",
    "2. State \n",
    "3. Cost\n",
    "\n",
    "It makes use of the following built in functions: \n",
    "1. \\_\\_hash\\_\\_ : This provides the hash value for every node, which is required for the hashset\n",
    "2. \\_\\_eq\\_\\_ : To check if 2 nodes are equal (Operator overload)\n",
    "3. \\_\\_ne\\_\\_ : To check if 2 nodes are not equal (Operator overload)\n",
    "4. \\_\\_str\\_\\_ : To get string representation of state in node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, pcost, hcost):\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.pcost = pcost\n",
    "        self.hcost = hcost\n",
    "        self.cost = pcost + hcost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten()))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorityQueue\n",
    "The Priority Queue is used to store the nodes along with the cost, and pop the node having the least cost for BFS\n",
    "\n",
    "It makes use of the following functions: \n",
    "1. push : Add node to queue\n",
    "2. pop : Pop node having least cost\n",
    "3. is_empty : To check if queue is empty\n",
    "4. \\_\\_len\\_\\_ : To get length of queue\n",
    "5. \\_\\_str\\_\\_ : To get string representation of queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        \n",
    "    def push(self, node):\n",
    "        self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        \n",
    "        next_state = None\n",
    "        state_cost = 10**18\n",
    "        index = -1\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if self.queue[i].cost<state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        \n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        \n",
    "        return len(self.queue)==0\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)\n",
    "        \n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "The environment is what the agent plays in. It has the following entities:\n",
    "1. actions : The actions defined in the environment\n",
    "2. depth: the maximum depth of the solution\n",
    "3. goal_state : The goal state of the environment\n",
    "4. start_state : The start state generated at the depth\n",
    "\n",
    "It has the following functions: \n",
    "1. get_start_state : returns the start state\n",
    "2. reached_goal : returns goal_state\n",
    "3. get_next_states : Given current state, it returns all possible next states\n",
    "4. generate_start_state : Given goal state and depth d, performs d moves to generate a start state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    def __init__(self, depth = None, goal_state = None):\n",
    "        self.actions = [1,2,3,4] #1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
    "        self.goal_state = goal_state\n",
    "        self.depth = depth\n",
    "        self.start_state = self.generate_start_state()\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        \n",
    "        past_state = goal_state\n",
    "        i=0\n",
    "        while i!= self.depth:\n",
    "            new_states = self.get_next_states(past_state)\n",
    "            choice = np.random.randint(low=0, high=len(new_states))\n",
    "            \n",
    "            if np.array_equal(new_states[choice], past_state):\n",
    "                continue\n",
    "            \n",
    "            past_state = new_states[choice]\n",
    "            i+=1\n",
    "            \n",
    "        return past_state\n",
    "    \n",
    "    def get_start_state(self):\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        \n",
    "        space = (0,0)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] == '_':\n",
    "                    space = (i,j)\n",
    "                    break\n",
    "        \n",
    "        new_states = []\n",
    "        \n",
    "        if space[0] > 0:# Move Up\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]-1, space[1]]\n",
    "            new_state[space[0]-1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[0] < 2: #Move down\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]+1, space[1]]\n",
    "            new_state[space[0]+1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        if space[1]<2: #Move right\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]+1]\n",
    "            new_state[space[0], space[1]+1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[1] > 0: #Move Left\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]-1]\n",
    "            new_state[space[0], space[1]-1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] != self.goal_state[i,j]:\n",
    "                    return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "The agent is the player who plays the game against the environment to win. It has the following entities:\n",
    "1. frontier : This is the priority queue used to store the nodes to be explored.\n",
    "2. explored : This is the dictionary which stores the explored nodes\n",
    "3. start_state : Stores the start state\n",
    "4. goal_state : Stores the goal state\n",
    "5. env : Stores the environment\n",
    "6. goal_node : Stores the goal node if found\n",
    "7. heuristic : Stores the heuristic function\n",
    "\n",
    "The agent has the following functions: \n",
    "1. run(): Is the function that explores the environment and finds the goal node. Uses the built in heuristic function to get the path costs\n",
    "2. print_nodes(): To print the path from the start node to goal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost=0)\n",
    "        self.frontier.push(init_node)\n",
    "        steps = 0\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            #print(curr_node.cost)\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "\n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                #print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            l = []\n",
    "            for state in next_states:\n",
    "\n",
    "                hcost = self.heuristic(state, goal_state)\n",
    "                node = Node(parent=curr_node, state=state, pcost=curr_node.pcost+1, hcost=hcost)\n",
    "                self.frontier.push(node)\n",
    "            steps += 1\n",
    "        \n",
    "        \n",
    "        return steps, self.soln_depth()\n",
    "    \n",
    "    def soln_depth(self):\n",
    "        node = self.goal_node\n",
    "        count = 0\n",
    "        while node is not None:\n",
    "            node = node.parent\n",
    "            count+=1\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Step: \",step)\n",
    "            print(node)\n",
    "            step+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the environment cannot spawn its own start and end states, we input the start state and end state to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic0(curr_state, goal_state):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic1(curr_state, goal_state):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if curr_state[i, j]!=goal_state[i,j]:\n",
    "                count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic2(curr_state, goal_state):\n",
    "    \n",
    "    dist = 0\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ele = curr_state[i, j]\n",
    "            goal_i, goal_j = np.where(goal_state==ele)\n",
    "            d = abs(goal_i[0] - i) + abs(goal_j[0] - j)\n",
    "            dist += d\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State: \n",
      "[['8' '1' '5']\n",
      " ['6' '_' '3']\n",
      " ['7' '4' '2']]\n",
      "Goal State: \n",
      "[['1' '2' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '6' '5']]\n"
     ]
    }
   ],
   "source": [
    "depth = 500\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "env = Environment(depth, goal_state)\n",
    "print(\"Start State: \")\n",
    "print(env.get_start_state())\n",
    "print(\"Goal State: \")\n",
    "print(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env = env, heuristic = heuristic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 21)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.978916168212891e-05 0.0\n",
      "50 0.02482998847961426 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-3dea75e40045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheuristic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtime_taken\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-361174c955a2>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mcurr_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrontier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m#print(curr_node.cost)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mnext_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplored\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-f6622daae0ff>\u001b[0m in \u001b[0;36mget_next_states\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#Move down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m--> 775\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[1;31m# Basic operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depths = np.arange(0,501,50)\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "times_taken = {}\n",
    "mems = {}\n",
    "for depth in depths:\n",
    "    \n",
    "    time_taken = 0\n",
    "    mem = 0\n",
    "    for i in range(100):\n",
    "        env = Environment(depth=depth, goal_state=goal_state)\n",
    "        agent = Agent(env = env, heuristic = heuristic2)\n",
    "        start_time = time()\n",
    "        agent.run()\n",
    "        end_time = time()\n",
    "        time_taken+=end_time - start_time\n",
    "        #mem+=sys.getsizeof(agent)\n",
    "    \n",
    "    time_taken/=100\n",
    "    mem = mem/100\n",
    "    times_taken[depth] = time_taken\n",
    "    mems[depth] = mem\n",
    "    print(depth, time_taken, mem)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.972095489501953e-05 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-58911d4a3692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheuristic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheuristic1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mtime_taken\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-8c00adab4b44>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mnext_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_node\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplored\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-c1ff519955eb>\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "depths = np.arange(0,501,50)\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "times_taken = {}\n",
    "mems = {}\n",
    "for depth in depths:\n",
    "    \n",
    "    time_taken = 0\n",
    "    mem = 0\n",
    "    for i in range(50):\n",
    "        env = Environment(depth=depth, goal_state=goal_state)\n",
    "        agent = Agent(env = env, heuristic = heuristic1)\n",
    "        start_time = time()\n",
    "        agent.run()\n",
    "        end_time = time()\n",
    "        time_taken+=end_time - start_time\n",
    "        #mem+=sys.getsizeof(agent)\n",
    "    \n",
    "    time_taken/=50\n",
    "    mem = mem/50\n",
    "    times_taken[depth] = time_taken\n",
    "    mems[depth] = mem\n",
    "    print(depth, time_taken, mem)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22936"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
