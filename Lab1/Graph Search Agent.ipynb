{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Search Agent\n",
    "\n",
    "The graph search agent requires an environment to define the following\n",
    "\n",
    "1. Start State\n",
    "2. Goal State\n",
    "3. Possible Actions\n",
    "\n",
    "We have to make a generalised agent, which reaches the goal state using the functions of the environment. Our agent will use BFS/DFS to reach to the goal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node\n",
    "The Node class greates the graph node. It has the following values\n",
    "1. Parent Node\n",
    "2. State \n",
    "3. Cost\n",
    "\n",
    "It makes use of the following built in functions: \n",
    "1. \\_\\_hash\\_\\_ : This provides the hash value for every node, which is required for the hashset\n",
    "2. \\_\\_eq\\_\\_ : To check if 2 nodes are equal (Operator overload)\n",
    "3. \\_\\_ne\\_\\_ : To check if 2 nodes are not equal (Operator overload)\n",
    "4. \\_\\_str\\_\\_ : To get string representation of state in node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, cost):\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.cost = cost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten()))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PriorityQueue\n",
    "The Priority Queue is used to store the nodes along with the cost, and pop the node having the least cost for BFS\n",
    "\n",
    "It makes use of the following functions: \n",
    "1. push : Add node to queue\n",
    "2. pop : Pop node having least cost\n",
    "3. is_empty : To check if queue is empty\n",
    "4. \\_\\_len\\_\\_ : To get length of queue\n",
    "5. \\_\\_str\\_\\_ : To get string representation of queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        \n",
    "    def push(self, node):\n",
    "        self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        \n",
    "        next_state = None\n",
    "        state_cost = 10**18\n",
    "        index = -1\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if self.queue[i].cost<state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        \n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        \n",
    "        return len(self.queue)==0\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)\n",
    "        \n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "The environment is what the agent plays in. It has the following entities:\n",
    "1. actions : The actions defined in the environment\n",
    "2. start_state : The starting state of the environment\n",
    "3. goal_state : The goal state of the environment\n",
    "\n",
    "It has the following functions: \n",
    "1. get_start_state : returns the start state\n",
    "2. reached_goal : returns goal_state\n",
    "3. get_next_states : Given current state, it returns all possible next states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    def __init__(self, depth = None, goal_state = None):\n",
    "        self.actions = [1,2,3,4] #1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
    "        self.goal_state = goal_state\n",
    "        self.depth = depth\n",
    "        self.start_state = self.generate_start_state()\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        \n",
    "        past_state = goal_state\n",
    "        i=0\n",
    "        while i!= self.depth:\n",
    "            new_states = self.get_next_states(past_state)\n",
    "            choice = np.random.randint(low=0, high=len(new_states))\n",
    "            \n",
    "            if np.array_equal(new_states[choice], past_state):\n",
    "                continue\n",
    "            \n",
    "            past_state = new_states[choice]\n",
    "            i+=1\n",
    "            \n",
    "        return past_state\n",
    "    \n",
    "    def get_start_state(self):\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        \n",
    "        space = (0,0)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] == '_':\n",
    "                    space = (i,j)\n",
    "                    break\n",
    "        \n",
    "        new_states = []\n",
    "        \n",
    "        if space[0] > 0:# Move Up\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]-1, space[1]]\n",
    "            new_state[space[0]-1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[0] < 2: #Move down\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]]  = new_state[space[0]+1, space[1]]\n",
    "            new_state[space[0]+1, space[1]] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        if space[1]<2: #Move right\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]+1]\n",
    "            new_state[space[0], space[1]+1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "            \n",
    "        if space[1] > 0: #Move Left\n",
    "            new_state = np.copy(state)\n",
    "            \n",
    "            val = new_state[space[0], space[1]]\n",
    "            new_state[space[0], space[1]] = new_state[space[0], space[1]-1]\n",
    "            new_state[space[0], space[1]-1] = val\n",
    "            \n",
    "            new_states.append(new_state)\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i,j] != self.goal_state[i,j]:\n",
    "                    return False\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, start_state, goal_state, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = start_state\n",
    "        self.goal_state = goal_state\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, cost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            #print(curr_node.cost)\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "\n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            l = []\n",
    "            for state in next_states:\n",
    "\n",
    "                hcost = self.heuristic(state, goal_state)\n",
    "                node = Node(parent=curr_node, state=state, cost=curr_node.cost+1+hcost)\n",
    "                self.frontier.push(node)\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Step: \",step)\n",
    "            print(node)\n",
    "            step+=1\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the environment cannot spawn its own start and end states, we input the start state and end state to the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 100\n",
    "goal_state = np.array([[1,2,3], [8,'_',4], [7,6,5]])\n",
    "env = Environment(depth, goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start State: \n",
      "[['6' '4' '3']\n",
      " ['1' '2' '7']\n",
      " ['_' '5' '8']]\n",
      "Goal State: \n",
      "[['1' '2' '3']\n",
      " ['8' '_' '4']\n",
      " ['7' '6' '5']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Start State: \")\n",
    "print(env.get_start_state())\n",
    "print(\"Goal State: \")\n",
    "print(goal_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic0(curr_state, goal_state):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic1(curr_state, goal_state):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if curr_state[i, j]!=goal_state[i,j]:\n",
    "                count+=1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic2(curr_state, goal_state):\n",
    "    \n",
    "    dist = 0\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ele = curr_state[i, j]\n",
    "            goal_i, goal_j = np.where(goal_state==ele)\n",
    "            d = abs(goal_i[0] - i) + abs(goal_j[0] - j)\n",
    "            dist += d\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env.get_start_state(), env.get_goal_state(), env, heuristic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n"
     ]
    }
   ],
   "source": [
    "agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
